{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "В цьому домашньому завданні ми проведемо додаткові експерименти для рішення задачі бінарної класифікації і створимо ваш новий submission на змагання на Kaggle.\n",
        "\n",
        "-----------\n",
        "\n",
        "\n",
        "**Завдання 0**. Завантажте дані `train.csv`, `test.csv`, `sample_submission.csv` зі змагання на Kaggle - шукайте посилання в уроці [Запрошення до участі у Kaggle-змаганні.](https://data-loves.kwiga.com/courses/machine-learning-dlia-liudei/domashnie-zavdannia-zmagannia-z-kaggle)  Для завантаження потрібно долучитись до змагання (натиснути кнопку \"Join\").\n",
        "\n",
        "\n",
        "**Завдання 1**. **Збираємо весь код з попереднього ДЗ в одному місці.** В лекційному ноутбуці `Логістична регресія з ScikitLearn. Повна ML задача.ipynb` ми познайомились з поняттям пайплайнів, а також я показала, як компактно виглядає рішення МЛ задачі, якщо ми зберемо весь код разом.\n",
        "\n",
        "Оскільки ми далі будемо робити експерименти, які включають ті самі етапи попередньої обробки, але інше моделювання - буде зручно мати весь код компактно і під рукою. Тому зараз ми займемось збором коду до купи :) Після цього завдання для подальших експериментів ви можете перенести частини розвʼязку взагалі в окремий `.py` файл, аби було зручно імпортувати функції.\n",
        "\n",
        "Зі свого рішення в попередньому домашньому завданні (`Логістична регресія з scikit learn.ipynb`) зберіть усі кроки розвʼязку задачі разом з використанням `sklearn.Pipeline` за прикладом з лекції.\n",
        "\n",
        "Ваш код нижче має містити\n",
        "1. Читання даних з файлу (поза пайплайном).\n",
        "2. Розбиття на тренувальний і валідаційний набори, де валідаційний містить 20% даних (поза пайплайном).\n",
        "3. Виділення категоріальних і числових колонок (поза пайплайном).\n",
        "4. Підготовку категоріальних і числових колонок (частина пайплайну). В прикладі в лекції ми оформлювали обробку числових і категоріальних колонок в окремі трансформери `numeric_transformer`, `categorical_cols`. Рекоемндую зробити саме так, так потім зручніше вносити зміни :)\n",
        "5. Тренування лог регресії (частина пайплайну).\n",
        "6. Запуск пайплайну на тренування на трен. даних (поза пайплайном).\n",
        "7. Запуск пайплайну на передбачення на трен і вал. даних і вимір метрик якості ROC-AUC + вивдення Confusion Matrix (поза пайплайном).\n",
        "8. Збереження моделі в формат joblib (поза пайплайном).\n",
        "\n",
        "Ви це все вже зробили в попереднтьому ДЗ! Тож, тут просто заадча все зібрати разом.\n",
        "\n",
        "Нижче я додала підказки, що покроково ви маєте зробити. Якщо ви почуваєтесь впевнено, можете видалити ці підказки і реалізувати все самостійно, або ж - просто заповнити пропуски.\n",
        "\n",
        "Завдання оцінюється в 10 балів. Головний результат - аби код в фіналі був робочий. Бо за не робочий нам гроші ніхто не заплатить :)"
      ],
      "metadata": {
        "id": "gJ2A6t3mdEed"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix, roc_auc_score, f1_score, roc_curve\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "import joblib\n",
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0XjWU0boj9hJ",
        "outputId": "41d6f7c9-0384-4a83-d4f0-62e6bd8000fc"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "raw_df = pd.read_csv(\"drive/MyDrive/Machine Learning для людей/data/bank/train.csv\")\n",
        "\n",
        "train_df, val_df = train_test_split(raw_df, test_size=0.2, random_state=42, stratify=raw_df['Exited'])\n",
        "\n",
        "target_col = 'Exited'\n",
        "input_cols = list(train_df.columns.drop([target_col, 'id', 'CustomerId', 'Surname']))\n",
        "numeric_cols = train_df[input_cols].select_dtypes(include=np.number).columns.tolist()\n",
        "categorical_cols = train_df[input_cols].select_dtypes(include='object').columns.tolist()\n",
        "\n",
        "X_train = train_df[input_cols]\n",
        "y_train = train_df[target_col]\n",
        "X_val = val_df[input_cols]\n",
        "y_val = val_df[target_col]\n",
        "\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('scaler', MinMaxScaler())\n",
        "])\n",
        "\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('encoder', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
        "])\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_transformer, numeric_cols),\n",
        "        ('cat', categorical_transformer, categorical_cols)\n",
        "    ])\n",
        "\n",
        "model_pipeline = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('classifier', LogisticRegression(solver='liblinear', random_state=42))\n",
        "])\n",
        "\n",
        "model_pipeline.fit(X_train, y_train)\n",
        "\n",
        "def evaluate_pipeline(pipeline, X, y, name):\n",
        "    preds = pipeline.predict(X)\n",
        "    probs = pipeline.predict_proba(X)[:, 1]\n",
        "\n",
        "    auc = roc_auc_score(y, probs)\n",
        "    f1 = f1_score(y, preds)\n",
        "    conf_mat = confusion_matrix(y, preds)\n",
        "\n",
        "    print(f\"\\n--- {name} Metrics ---\")\n",
        "    print(f\"AUROC: {auc:.4f}\")\n",
        "    print(f\"F1 Score: {f1:.4f}\")\n",
        "    print(\"Confusion Matrix:\")\n",
        "    print(conf_mat)\n",
        "    return probs\n",
        "\n",
        "train_probs = evaluate_pipeline(model_pipeline, X_train, y_train, \"Train\")\n",
        "val_probs = evaluate_pipeline(model_pipeline, X_val, y_val, \"Validation\")\n",
        "\n",
        "joblib.dump(model_pipeline, 'log_reg_pipeline.joblib')\n",
        "print(\"\\nПайплайн збережено в 'log_reg_pipeline.joblib'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l4meely0kCvg",
        "outputId": "9d3ff308-9950-4f00-86db-a28952344d91"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Train Metrics ---\n",
            "AUROC: 0.8824\n",
            "F1 Score: 0.6352\n",
            "Confusion Matrix:\n",
            "[[9177  381]\n",
            " [1128 1314]]\n",
            "\n",
            "--- Validation Metrics ---\n",
            "AUROC: 0.8797\n",
            "F1 Score: 0.6412\n",
            "Confusion Matrix:\n",
            "[[2271  119]\n",
            " [ 266  344]]\n",
            "\n",
            "Пайплайн збережено в 'log_reg_pipeline.joblib'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Завдання 2**. Такс, у нас з вами є вже готовий пайплайн. Давайте проведемо нові експерименти.\n",
        "\n",
        "  Додайте в попередню обробку числових колонок генерацію polinomal features до степені 2 включно. Для цього створіть новий препроцесор і створіть новий пайплайн.\n",
        "\n",
        "  Запустіть пайплайн на тренування і виведіть метрики для тренувального і валідаційного набору. Напишіть, як вам модель? Чи спостерігається в цій моделі overfit чи underfit? Чи ця модель добре генералізує?"
      ],
      "metadata": {
        "id": "PXrc2NCa5lAK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "\n",
        "numeric_transformer_poly = Pipeline(steps=[\n",
        "    ('poly', PolynomialFeatures(degree=2, include_bias=False)),\n",
        "    ('scaler', MinMaxScaler())\n",
        "])\n",
        "\n",
        "preprocessor_poly = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_transformer_poly, numeric_cols),\n",
        "        ('cat', categorical_transformer, categorical_cols)\n",
        "    ])\n",
        "\n",
        "poly_pipeline = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor_poly),\n",
        "    ('classifier', LogisticRegression(solver='liblinear', random_state=42))\n",
        "])\n",
        "\n",
        "print(\"Навчання моделі з поліноміальними ознаками...\")\n",
        "poly_pipeline.fit(X_train, y_train)\n",
        "\n",
        "print(\"\\nРезультати з поліноміальними ознаками:\")\n",
        "evaluate_pipeline(poly_pipeline, X_train, y_train, \"Train Poly\")\n",
        "evaluate_pipeline(poly_pipeline, X_val, y_val, \"Validation Poly\")"
      ],
      "metadata": {
        "id": "TjcmWMTOOjJ1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "852404eb-b97b-44df-ffd0-d6a9f5453113"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Навчання моделі з поліноміальними ознаками...\n",
            "\n",
            "Результати з поліноміальними ознаками:\n",
            "\n",
            "--- Train Poly Metrics ---\n",
            "AUROC: 0.9110\n",
            "F1 Score: 0.6754\n",
            "Confusion Matrix:\n",
            "[[9221  337]\n",
            " [1025 1417]]\n",
            "\n",
            "--- Validation Poly Metrics ---\n",
            "AUROC: 0.9099\n",
            "F1 Score: 0.6771\n",
            "Confusion Matrix:\n",
            "[[2283  107]\n",
            " [ 243  367]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.5836549 , 0.03540179, 0.06650954, ..., 0.01911462, 0.04267899,\n",
              "       0.0678362 ])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Завдання 3**. Тепер давайте створимо ще новий пайплайн, тільки тепер поліноміальні ознаки згенеруємо до степені 4. Зробіть висновок про якість моделі. Якщо вам подобається резульат якоїсь з моделей в цьому ДЗ - рекомендую зробити submission в змаганні."
      ],
      "metadata": {
        "id": "tkmEmHaP8Pen"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "numeric_transformer_poly4 = Pipeline(steps=[\n",
        "    ('poly', PolynomialFeatures(degree=4, include_bias=False)),\n",
        "    ('scaler', MinMaxScaler())\n",
        "])\n",
        "\n",
        "preprocessor_poly4 = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_transformer_poly4, numeric_cols),\n",
        "        ('cat', categorical_transformer, categorical_cols)\n",
        "    ])\n",
        "\n",
        "poly4_pipeline = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor_poly4),\n",
        "    ('classifier', LogisticRegression(solver='liblinear', random_state=42, max_iter=1000))\n",
        "])\n",
        "\n",
        "print(\"⏳ Навчання моделі\")\n",
        "poly4_pipeline.fit(X_train, y_train)\n",
        "\n",
        "print(\"\\n--- Результати (Degree 4) ---\")\n",
        "evaluate_pipeline(poly4_pipeline, X_train, y_train, \"Train Poly 4\")\n",
        "evaluate_pipeline(poly4_pipeline, X_val, y_val, \"Validation Poly 4\")\n",
        "\n",
        "test_raw_df = pd.read_csv(\"drive/MyDrive/Machine Learning для людей/data/bank/test.csv\")\n",
        "\n",
        "test_probs_poly4 = poly4_pipeline.predict_proba(test_raw_df)[:, 1]\n",
        "\n",
        "submission_poly4 = pd.DataFrame({\n",
        "    'id': test_raw_df['id'],\n",
        "    'Exited': test_probs_poly4\n",
        "})\n",
        "submission_poly4.to_csv('submission_poly_4.csv', index=False)\n",
        "print(\"\\n Файл 'submission_poly_4.csv' створено.\")"
      ],
      "metadata": {
        "id": "OsT-MDWuOkDY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "918ea2cb-888f-4fe3-92d4-3e6fb17c84b5"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⏳ Навчання моделі\n",
            "\n",
            "--- Результати (Degree 4) ---\n",
            "\n",
            "--- Train Poly 4 Metrics ---\n",
            "AUROC: 0.9317\n",
            "F1 Score: 0.7286\n",
            "Confusion Matrix:\n",
            "[[9203  355]\n",
            " [ 839 1603]]\n",
            "\n",
            "--- Validation Poly 4 Metrics ---\n",
            "AUROC: 0.9283\n",
            "F1 Score: 0.7191\n",
            "Confusion Matrix:\n",
            "[[2284  106]\n",
            " [ 208  402]]\n",
            "\n",
            " Файл 'submission_poly_4.csv' створено.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Завдання 4. Перенавчання і регуляризація**.\n",
        "\n",
        "  Скачайте набір даних `regression_data.csv`. Звичайте набір даних з `regression_data.csv`, розбийте на train і test (в тест 20%) і натренуйте модель лінійної регресії з масштабуванням числових ознак і поліноміальними ознаками до степені **5 включно**.\n",
        "\n",
        "  Виміряйте якість прогностичної моделі і зробіть висновок, чи модель хороша, чи вона добре генералізує?\n"
      ],
      "metadata": {
        "id": "ozN2ONZGCBS6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import PolynomialFeatures, MinMaxScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "df_reg = pd.read_csv(\"drive/MyDrive/Machine Learning для людей/data/regression_data.csv\")\n",
        "\n",
        "X = df_reg.drop(columns=['target'])\n",
        "y = df_reg['target']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "reg_pipeline = Pipeline([\n",
        "    ('poly', PolynomialFeatures(degree=5, include_bias=False)),\n",
        "    ('scaler', MinMaxScaler()),\n",
        "    ('model', LinearRegression())\n",
        "])\n",
        "\n",
        "reg_pipeline.fit(X_train, y_train)\n",
        "\n",
        "def evaluate_regression(pipeline, X, y, name):\n",
        "    preds = pipeline.predict(X)\n",
        "    mse = mean_squared_error(y, preds)\n",
        "    rmse = np.sqrt(mse)\n",
        "    r2 = r2_score(y, preds)\n",
        "    print(f\"--- {name} Metrics ---\")\n",
        "    print(f\"RMSE (Середньоквадратична помилка): {rmse:.4f}\")\n",
        "    print(f\"R2 Score (Точність): {r2:.4f}\")\n",
        "    return r2\n",
        "\n",
        "print(\"Результати моделі з поліномом 5-го ступеня:\")\n",
        "r2_train = evaluate_regression(reg_pipeline, X_train, y_train, \"TRAIN\")\n",
        "r2_test = evaluate_regression(reg_pipeline, X_test, y_test, \"TEST\")"
      ],
      "metadata": {
        "id": "xbl0jQ3WOlgn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04666dde-a022-438e-d93a-e95ce5e10de2"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Результати моделі з поліномом 5-го ступеня:\n",
            "--- TRAIN Metrics ---\n",
            "RMSE (Середньоквадратична помилка): 0.0000\n",
            "R2 Score (Точність): 1.0000\n",
            "--- TEST Metrics ---\n",
            "RMSE (Середньоквадратична помилка): 12.3633\n",
            "R2 Score (Точність): 0.9345\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "на тренуванні помилка нульова, а на тесті з'являється значна похибка, свідчить про перенавчання. Модель із поліномом 5-го ступеня стала занадто \"гнучкою\". Замість того щоб намалювати плавну лінію тренду, вона почала вигинатися, щоб пройти через кожну, навіть випадкову, точку тренувального набору. Через це на нових даних вона помиляється більше, ніж могла б простіша модель.\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "JER5wIb5rgM_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Завдання 5**. Натренуйте моделі Lasso(), Ridge(), ElasaticNet() на цих даних (з поліном ознаками до степені 20 включно), порівняйте якість з тою, яка була отримана з лінійною регресією. Яка модель найкраще генералізує і чому на ваш погляд (можливо треба буде для відповіді зробити додатковий аналіз ознак)?"
      ],
      "metadata": {
        "id": "JNUt-Q6UHkn7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression, Lasso, Ridge, ElasticNet\n",
        "from sklearn.preprocessing import PolynomialFeatures, MinMaxScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "try:\n",
        "    df_reg = pd.read_csv(\"drive/MyDrive/Machine Learning для людей/data/regression_data.csv\")\n",
        "except FileNotFoundError:\n",
        "    print(\"⚠️ Файл не знайдено!\")\n",
        "\n",
        "X = df_reg.drop(columns=['target'])\n",
        "y = df_reg['target']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "def get_pipeline(model):\n",
        "    return Pipeline([\n",
        "        ('poly', PolynomialFeatures(degree=20, include_bias=False)),\n",
        "        ('scaler', MinMaxScaler()),\n",
        "        ('model', model)\n",
        "    ])\n",
        "\n",
        "models = [\n",
        "    ('LinearRegression', LinearRegression()),\n",
        "    ('Lasso', Lasso(alpha=0.1, max_iter=10000, random_state=42)),\n",
        "    ('Ridge', Ridge(alpha=1.0, random_state=42)),\n",
        "    ('ElasticNet', ElasticNet(alpha=0.1, l1_ratio=0.5, max_iter=10000, random_state=42))\n",
        "]\n",
        "\n",
        "print(f\"{'Model':<20} | {'Train R2':<10} | {'Test R2':<10} | {'Test RMSE':<10}\")\n",
        "print(\"-\" * 65)\n",
        "\n",
        "for name, model in models:\n",
        "    pipeline = get_pipeline(model)\n",
        "    pipeline.fit(X_train, y_train)\n",
        "\n",
        "    train_pred = pipeline.predict(X_train)\n",
        "    test_pred = pipeline.predict(X_test)\n",
        "\n",
        "    r2_train = r2_score(y_train, train_pred)\n",
        "    r2_test = r2_score(y_test, test_pred)\n",
        "    rmse_test = np.sqrt(mean_squared_error(y_test, test_pred))\n",
        "\n",
        "    print(f\"{name:<20} | {r2_train:<10.4f} | {r2_test:<10.4f} | {rmse_test:<10.4f}\")\n",
        "\n",
        "print(\"\\n--- Lasso ---\")\n",
        "lasso_pipeline = get_pipeline(Lasso(alpha=0.1, max_iter=10000, random_state=42))\n",
        "lasso_pipeline.fit(X_train, y_train)\n",
        "lasso_model = lasso_pipeline.named_steps['model']\n",
        "\n",
        "total_features = len(lasso_model.coef_)\n",
        "non_zero_features = np.sum(np.abs(lasso_model.coef_) > 1e-4)\n",
        "\n",
        "print(f\"Всього створено ознак (поліном 20): {total_features}\")\n",
        "print(f\"Lasso залишила важливих ознак: {non_zero_features}\")\n",
        "print(f\"Lasso викинула (занулила) сміття: {total_features - non_zero_features}\")"
      ],
      "metadata": {
        "id": "y93ItPYdOnpE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2e49bd9-dc9d-433b-a93c-b532798b0a53"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model                | Train R2   | Test R2    | Test RMSE \n",
            "-----------------------------------------------------------------\n",
            "LinearRegression     | 1.0000     | 0.8947     | 15.6743   \n",
            "Lasso                | 0.9993     | 0.9996     | 1.0046    \n",
            "Ridge                | 0.9620     | -1.5125    | 76.5627   \n",
            "ElasticNet           | 0.8184     | -5.6896    | 124.9292  \n",
            "\n",
            "--- Lasso ---\n",
            "Всього створено ознак (поліном 20): 53129\n",
            "Lasso залишила важливих ознак: 1\n",
            "Lasso викинула (занулила) сміття: 53128\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Найкраще генералізує модель Lasso. Вона показала майже ідеальний результат на тестових даних ($R^2 = 0.9996$) і найменшу помилку ($RMSE \\approx 1.0$), при цьому результат на тренуванні та тесті майже однаковий, що свідчить про повну відсутність перенавчання."
      ],
      "metadata": {
        "id": "tcpS2xJbwrbj"
      }
    }
  ]
}